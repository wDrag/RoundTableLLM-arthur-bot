# Web3 Product Ideation SOP (Demo-First, Low-Interaction, High-Confidence) — Final

This SOP is optimized for **idea + demo** phases. It explicitly **excludes GTM**, growth, distribution strategy, and user acquisition planning. We can still discuss market/user/audience strictly to (a) pick the right problem/persona and (b) craft a compelling demo narrative.

---

## 0) Design Goals

1) **Few interactions**: minimize back-and-forth.  
2) **High quality per turn**: each response is a complete deliverable (not partial).  
3) **Low correction cost**: reduce “wrong direction” via a strict **Contract + Assumption Ledger** before any deep work.  
4) **Confidence-first**: before delivering, the AI must run a built-in quality gate and retry internally when confidence is low.

---

## 1) Operating Rules (Non-Negotiable)

### 1.1 Demo-Only Scope
In-scope:
- Problem framing, persona/JTBD, UX flow, technical primitives, trust/verification model, architecture, feasibility, risks, demo scripts, acceptance tests, hackathon packaging.

Out-of-scope:
- GTM, distribution strategy, viral loops, acquisition channels, growth metrics, retention marketing, monetization strategy (unless *strictly needed* to explain mechanism in demo).

### 1.2 One-Turn Deliverables + Stop Rule
Each stage produces a **finished artifact**.  
After each artifact, there is exactly **one stop question**: “Approved to proceed to the next stage?”

### 1.3 Question Budget
The AI must ask **8–12 questions max** at the start (Stage 0).  
No more “drip questions” unless:
- a critical ambiguity blocks correctness, or
- confidence would drop below 0.8 without one key clarification.

### 1.4 Assumption Ledger
Any unconfirmed point must be listed as:
- Confirmed / Chosen default / Unconfirmed  
The AI must never silently assume key things (persona, chain, trust model, constraints).

---

## 2) Core Output Artifacts (What You Will Receive)

1) **Idea/Demo Contract v0.1** + Assumption Ledger (Stage 0)  
2) **Evidence Pack** (patterns + anti-patterns + technical palette) (Stage 1)  
3) **Problem Framing** (6 statements → 2 theses + 1 fallback) (Stage 2)  
4) **Ideation 10 → 5** (diversity-guarded + scored) (Stage 3)  
5) **One-Pager Spec + Build Plan** (backlog, acceptance tests, demo scripts) (Stage 4)

Each artifact includes a **Quality Appendix** (Section 4) when the work is complex.

---

## 3) Workflow Stages (Demo-First)

### Stage 0 — Intake + Idea/Demo Contract (Mandatory)
**Purpose:** eliminate misalignment before research/ideation.

User provides (fast):
- answers to the Intake Questions (Section 5).

AI produces:
- **Idea/Demo Contract v0.1** (1 page) containing:
  - Goal: what the demo must wow on (choose up to 2)
  - Non-goals (top 3)
  - Persona + JTBD + 30s first action
  - Constraints: time, team, chain, dependencies, open-source, demo format
  - Demo Definition of Done:
    - Demo 30s script (5–7 steps)
    - Demo 3 minutes script (10–15 steps)
    - Judge takeaway (1 sentence)
  - Trust & Verification Model (MVP):
    - Onchain: state/settlement
    - Offchain: components (if any)
    - Assumptions + failure modes
  - Research depth: Lite / Standard (no GTM research)
  - Scoring weights (demo-only scorecard)
  - Kill-criteria (2–3 “fail = drop” rules)
- **Assumption Ledger** (Confirmed / Chosen default / Unconfirmed)

Acceptance test:
- Two teammates can restate contract with ≥80% alignment.

Stop rule:
- AI asks exactly one question: **“Approve Contract v0.1 to proceed to Stage 1?”**

---

### Stage 1 — Evidence Pack (Prior Art + Demo Pitfalls + Technical Palette)
**Purpose:** learn what wins in demos; avoid known failure modes.

User optionally provides:
- 0–5 links (hackathon page, winners, competitor docs, inspirations).

AI produces (1–2 pages):
- 8–12 **demo-winning patterns** (UX + flow + proof display + setup minimization)
- 3–5 **anti-patterns** (why demos fail)
- **Technical palette**: 3–6 primitives suitable for constraints + trade-offs
- Optional: “Opportunity Map” (3 gaps worth building)

Acceptance test:
- Each pattern has 1 concrete implication for the demo design.

Stop rule:
- “Approve patterns/palette to proceed to Stage 2?”

---

### Stage 2 — Problem Framing (Choose Thesis Before Ideation)
**Purpose:** lock the right problem + demo hook before generating ideas.

AI produces:
- 6 problem statements (no buzzwords; pitchable in 20s)
- 2 strong theses + 1 fallback
Each thesis must include:
- Persona + JTBD in 30s
- Core Web3 lever(s): ownership/verifiability/composability/settlement/incentives (if relevant)
- Minimal trust model: what is provable vs trusted
- Demo hook (the wow moment)

Acceptance test:
- A 20s spoken pitch is clear without jargon.

Stop rule:
- “Choose Thesis A/B or Fallback (or tweak one sentence). Approve to proceed to Stage 3?”

---

### Stage 3 — Ideation 10 → 5 (Diversity Guard + Pre-Mortem + Scoring)
**Purpose:** generate diversity, then keep only high-quality demoable ideas.

Diversity rule:
Each idea must differ by ≥2 of these 5 axes:
1) Persona  
2) Demo core loop  
3) Web3 lever  
4) Trust model  
5) Wow mechanism (UX/proof/latency/composability/automation)

AI produces:
- 10 rough ideas (1–2 lines)
- Pre-mortem (1 line each): how it fails in a demo
- Scorecard table → filter down to **Top 5**

For each Top 5 idea:
- One-liner
- Demo 30s steps
- Core loop (action → visible outcome → repeat reason)
- Trust & verification model
- Architecture sketch (onchain/offchain)
- Kill-criteria (1 sentence)
- 1 dev objection + 1 judge objection

Acceptance test:
- At least 2 ideas are eliminated for lacking demo reliability or lacking real Web3 leverage.

Stop rule:
- “Select 1–2 ideas to proceed to Stage 4.”

---

### Stage 4 — One-Pager Spec + Build Plan (Ship the Demo)
**Purpose:** turn chosen idea into a buildable, testable demo plan.

AI produces:
- One-pager spec (1 page)
- Backlog 10–14 days (20–40 tasks)
- 10 acceptance tests (happy path + abuse + correctness)
- Demo scripts:
  - 30s demo script
  - 3-minute demo script
- Repo/run instructions (local/devnet/test validator)

Acceptance test:
- Demo can be recorded reliably without manual patching.

Stop rule:
- “Approve spec/plan; optionally request a pitch deck outline.”

---

## 4) Quality Gate (Mandatory for Complex Work)

Every complex deliverable (Stages 0–4) must include a **Quality Appendix**.

### 4.1 The 5-Step Framework

1) **DECOMPOSE**
- List 3–6 sub-problems being solved.
- Restate in-scope/out-of-scope (must include “no GTM”).

2) **SOLVE**
- Provide the solution for each sub-problem.
- Attach confidence per sub-problem: **0.0–1.0**
- List assumptions with status:
  - Confirmed / Chosen default / Unconfirmed

3) **VERIFY**
- Logic check: contradictions?
- Completeness check: missing required sections?
- Bias check: overly tech/overly UX/overly speculative?
- Scope check: any GTM leakage?
- Facts: if any external facts are used, cite sources; if none, explicitly state “no external facts used”.

4) **SYNTHESIZE**
- Summarize 1–3 actionable conclusions/decisions.
- Compute **weighted confidence** (weights proportional to importance; typically feasibility + demo reliability weigh highest).

5) **REFLECT (Only if weighted confidence < 0.8)**
- Identify 1–3 weaknesses that drive uncertainty.
- Retry *within the same turn* using one or more:
  - offer A/B alternatives,
  - tighten assumptions (reduce ambiguity),
  - cut scope (increase certainty),
  - add acceptance tests / fallback demo mode.
- Provide updated synthesis after retry.

---

## 5) Stage 0 Intake Questions (10 Questions Max)

Answer these once; the AI then returns Contract v0.1 and asks one approval question.

1) Demo wow axis (pick up to 2): **UX / privacy / speed-latency / verifiable proofs / composability / agent automation / novel mechanic**  
2) Context: hackathon/internal demo? Deadline date?  
3) Persona (max 2) and what they do in the first 30 seconds?  
4) Top 3 non-goals (very specific; “hard bans”).  
5) Chain/ecosystem fixed or chain-agnostic?  
6) Team size + strengths (FE/SC/crypto) + real available dev days.  
7) Allowed trusted components in MVP: **indexer / relayer / executor / oracle / committee / none**  
8) Demo surface: **web app / mobile / Telegram bot / CLI / onchain-only**  
9) Preference: **trust-minimized** vs **demo-first** (trusted allowed but explicit).  
10) Up to 0–5 reference links you want the AI to imitate (UX/architecture/demo style).

---

## 6) Demo-Only Scorecard (No GTM)

Scored 0–5 with short justification:
1) Problem clarity (judge gets it in 20s)  
2) UX novelty (wow without confusion)  
3) Demo reliability (low setup, low dependencies, low breakpoints)  
4) Web3-nativeness (Web3 lever is core, not cosmetic)  
5) Trust & verification clarity (provable vs trusted, failure modes explicit)  
6) Technical defensibility (harder to copy)  
7) Feasibility (fits time/team)  
8) Security/abuse risk (identified + minimal guardrails)  
9) Track/sponsor fit (if applicable)

Meta-rule:
- Each idea also has “Idea confidence” (0.0–1.0).  
- If idea confidence < 0.75, it must include a scope cut or fallback demo mode.

---

## 7) Runnable Artifacts

### 7.1 Demo-Only Scorecard JSON
```json
{
  "scorecard": {
    "weights": {
      "problem_clarity": 0.14,
      "ux_novelty": 0.14,
      "demo_reliability": 0.14,
      "web3_nativeness": 0.12,
      "trust_verification_clarity": 0.12,
      "technical_defensibility": 0.10,
      "feasibility": 0.10,
      "security_abuse_risk": 0.08,
      "track_sponsor_fit": 0.06
    },
    "scale": "0-5",
    "notes_required": true,
    "kill_criteria_required": true
  },
  "idea_diversity_rules": {
    "must_differ_on_at_least": 2,
    "dimensions": ["persona", "demo_core_loop", "web3_lever", "trust_model", "wow_mechanism"]
  },
  "acceptance_bar": {
    "min_weighted_score": 3.7,
    "must_have": ["demo_in_30_seconds", "trust_model_explicit", "web3_lever_is_core", "repeatable_demo_flow"]
  }
}
